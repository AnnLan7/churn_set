{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#Caricamento dataset\n",
    "dataset_path = './WA_Fn-UseC_-Telco-Customer-Churn.train.csv'\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "dataset['Churn'] = dataset['Churn'].map({'Yes':1, 'No':0})\n",
    "# 'No internet service' and 'No phone service' mean that they do not have the service so it is equivalent to 'No'\n",
    "# Should not be missing data\n",
    "dataset['MultipleLines'] = dataset['MultipleLines'].replace({'No phone service' : 'No'})\n",
    "for i in [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies']: \n",
    "    dataset[i]  = dataset[i].replace({'No internet service' : 'No'})\n",
    "#Removing null values/ missing data\n",
    "#dataset['TotalCharges'] = dataset[\"TotalCharges\"].replace(\" \",np.NaN)\n",
    "#dataset = dataset.dropna(axis=0)\n",
    "#only 10, does not change much (worse results)\n",
    "\n",
    "# customerID is a value unique for each row, so it is not useful as a feature\n",
    "features = ['gender', 'SeniorCitizen', 'Partner',\n",
    "       'Dependents', 'tenure', 'PhoneService', 'MultipleLines',\n",
    "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "       'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "dataset.index = dataset['customerID']\n",
    "dataset = dataset.drop(columns='customerID')\n",
    "\n",
    "# Encoding strings of the data set into labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column in features:\n",
    "    dataset[column] = le.fit_transform(dataset[column])\n",
    "    \n",
    "#Separate features from y\n",
    "y = dataset['Churn']\n",
    "X = dataset[features]\n",
    "\n",
    "# Create training set and validation set \n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0, test_size=0.33)\n",
    "\n",
    "# More processing\n",
    "sc = StandardScaler()\n",
    "train_X = pd.DataFrame(sc.fit_transform(train_X))\n",
    "val_X = pd.DataFrame(sc.fit_transform(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "predicted = model.predict(val_X)\n",
    "mae = mean_absolute_error(val_y,predicted)\n",
    "train_accuracy = model.score(train_X,train_y)*100\n",
    "test_accuracy = model.score(val_X,val_y)*100\n",
    "\n",
    "print('Mean absolute error: ')\n",
    "print(mae)\n",
    "print('Training set accuracy: ')\n",
    "print(train_accuracy)\n",
    "print('Test set accuracy: ')\n",
    "print(test_accuracy)\n",
    "# max ~0.19 error with ~79-~80 -> best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model,val_X,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "model.fit(train_X,train_y)\n",
    "\n",
    "predicted = model.predict(val_X)\n",
    "mae = mean_absolute_error(val_y,predicted)\n",
    "train_accuracy = model.score(train_X,train_y)*100\n",
    "test_accuracy = model.score(val_X,val_y)*100\n",
    "\n",
    "print(predicted)\n",
    "print(mae)\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#best=[0,0,0,0]\n",
    "#for i in range(1,10):\n",
    "#    model = DecisionTreeClassifier(random_state=0, max_depth=i)\n",
    "#    model.fit(train_X,train_y)\n",
    "#    predicted = model.predict(val_X)\n",
    "#    print(i)\n",
    "#    mae = mean_absolute_error(val_y,predicted)\n",
    "#    print(predicted)\n",
    "#    train_accuracy = model.score(train_X,train_y)*100\n",
    "#    test_accuracy = model.score(val_X,val_y)*100\n",
    "#    print(mae)\n",
    "#    print(train_accuracy)\n",
    "#    print(test_accuracy)\n",
    "#    if test_accuracy > best[2]:\n",
    "#        best[0] = i\n",
    "#        best[1] = train_accuracy\n",
    "#        best[2] = test_accuracy\n",
    "#        best[3] = mae\n",
    "#print(best)\n",
    "#Best is ~0.21 with ~78-~78 and max_depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=54,n_jobs=-1)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "predicted = model.predict(val_X)\n",
    "mae = mean_absolute_error(val_y,predicted)\n",
    "\n",
    "train_accuracy = model.score(train_X,train_y)*100\n",
    "test_accuracy = model.score(val_X,val_y)*100\n",
    "\n",
    "print(predicted)\n",
    "print(mae)\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#results=[]\n",
    "#best=[0,0,0,0]\n",
    "#for i in range(1,100):\n",
    "#    model = KNeighborsClassifier(n_neighbors=i,n_jobs=-1)\n",
    "#    model.fit(train_X, train_y)\n",
    "#    predicted = model.predict(val_X)\n",
    "#    print(i)\n",
    "#    mae = mean_absolute_error(val_y,predicted)\n",
    "#    print(predicted)\n",
    "#    train_accuracy = model.score(train_X,train_y)*100\n",
    "#    test_accuracy = model.score(val_X,val_y)*100\n",
    "#    print(mae)\n",
    "#    print(train_accuracy)\n",
    "#    print(test_accuracy)\n",
    "#    results.append(mae) \n",
    "#    if test_accuracy > best[2]:\n",
    "#        best[0] = i\n",
    "#        best[1] = train_accuracy\n",
    "#        best[2] = test_accuracy\n",
    "#        best[3] = mae\n",
    "#from statistics import mean\n",
    "#mean(results)\n",
    "#print(best)\n",
    "# Best is ~78-~79 with ~0.20 error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to check if removing some features gets better results, but is this leaking?\n",
    "# Best is 78-81 removing StreamingMovies, InternetService, gender, PaperlessBilling, SeniorCitizen\n",
    "# After removing null values in TotalCharges, 80-80 removing PaperlessBilling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "changed_best = True\n",
    "best=[0,0,0]\n",
    "deleted_features = []\n",
    "train_X_copy = train_X\n",
    "val_X_copy = val_X\n",
    "\n",
    "while changed_best:\n",
    "    \n",
    "    last_removed = -1\n",
    "    changed_best = False\n",
    "    \n",
    "    for i in train_X_copy.columns:\n",
    "        \n",
    "        tr_X = train_X_copy.drop(columns=i)\n",
    "        v_X = val_X_copy.drop(columns=i)\n",
    "        \n",
    "        model = LogisticRegression(n_jobs=-1)\n",
    "        model.fit(tr_X, train_y)\n",
    "        \n",
    "        predicted = model.predict(v_X)\n",
    "        mae = mean_absolute_error(val_y,predicted)\n",
    "        train_accuracy = model.score(tr_X,train_y)*100\n",
    "        test_accuracy = model.score(v_X,val_y)*100\n",
    "        \n",
    "        if test_accuracy > best[1]:\n",
    "            best[0] = train_accuracy\n",
    "            best[1] = test_accuracy\n",
    "            best[2] = mae\n",
    "            changed_best = True\n",
    "            last_removed = i\n",
    "            \n",
    "    if changed_best:\n",
    "        train_X_copy = train_X_copy.drop(columns=last_removed)\n",
    "        val_X_copy = val_X_copy.drop(columns=last_removed)\n",
    "        deleted_features.append(last_removed)\n",
    "        \n",
    "    print(best)\n",
    "    print(deleted_features)\n",
    "    for i in deleted_features:\n",
    "        print(features[i-1])\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation functions\n",
    "#predicted = model.predict(val_X)\n",
    "#mae = mean_absolute_error(val_y,predicted)\n",
    "#train_accuracy = model.score(train_X,train_y)*100\n",
    "#test_accuracy = model.score(val_X,val_y)*100\n",
    "#print('Mean absolute error: ')\n",
    "#print(mae)\n",
    "#print('Training set accuracy: ')\n",
    "#print(train_accuracy)\n",
    "#print('Test set accuracy: ')\n",
    "#print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
